# V3.1 Relationship Ontology

**Version**: 1.0
**Date**: 2025-10-16
**Status**: Week 2 Design Document

---

## Philosophy: Causal Semantics, Not Generic Association

YARNNN v3.1 relationships capture **causality** and **logical dependencies**, not just "this relates to that."

**Core Principle**: Relationships must answer **"why"** and **"what depends on"** questions, not just "what's similar."

**Examples**:
- ❌ Bad: "Login page" relates to "Authentication system" (generic, obvious)
- ✅ Good: "Rate limiting implementation" **addresses** "Brute force vulnerability" (causal, actionable)

---

## The 4 Causal Relationship Types

### 1. `addresses` - Solution Addresses Problem

**Semantic Meaning**: A solution, action, or insight that directly addresses, solves, or mitigates a problem, constraint, or issue.

**Direction**: Solution → Problem (forward: what does this address? backward: what addresses this?)

**Valid Type Pairs**:
```
FROM types: action, insight, objective, solution, finding, decision
TO types: problem, constraint, issue, challenge, risk, gap
```

**Semantic Criteria** (for LLM verification):
1. The FROM block describes a concrete action, solution, or approach
2. The TO block describes a problem, constraint, or undesirable state
3. The FROM block **explicitly or implicitly mitigates/solves** the TO block
4. The relationship is **causal**: implementing FROM would reduce/eliminate TO

**Examples**:

✅ **Valid `addresses` relationships**:
```
FROM: "Implement rate limiting on login endpoint (5 attempts per minute)"
TO: "User authentication vulnerable to brute force attacks"
Reasoning: Rate limiting directly mitigates brute force vulnerability
```

```
FROM: "Add database indexes on user_id and created_at columns"
TO: "Dashboard query taking 3+ seconds to load user activity"
Reasoning: Indexes directly solve the slow query problem
```

```
FROM: "Introduce daily standup meetings at 9am"
TO: "Team members unaware of blockers until end of sprint"
Reasoning: Standups directly address communication gap
```

❌ **Invalid `addresses` relationships**:
```
FROM: "Login page UI redesigned"
TO: "Authentication system"
Reasoning: Not a problem being addressed, just a related feature
```

```
FROM: "Database migration completed"
TO: "Database schema needs updating"
Reasoning: This is temporal completion, not addressing (use depends_on)
```

**LLM Verification Prompt**:
```
Does "{FROM}" directly address, solve, or mitigate the problem described in "{TO}"?

Criteria:
- FROM must describe an action/solution/approach
- TO must describe a problem/constraint/undesirable state
- There must be a clear causal link (implementing FROM reduces TO)

Answer: Yes/No with confidence 0.0-1.0
```

---

### 2. `supports` - Evidence Supports Claim

**Semantic Meaning**: Evidence, data, or findings that support, validate, or strengthen a claim, objective, hypothesis, or principle.

**Direction**: Evidence → Claim (forward: what does this support? backward: what supports this?)

**Valid Type Pairs**:
```
FROM types: fact, finding, metric, evidence, quote, data, observation
TO types: objective, insight, hypothesis, principle, decision, conclusion
```

**Semantic Criteria** (for LLM verification):
1. The FROM block describes factual evidence, data, or observations
2. The TO block describes a claim, hypothesis, or conclusion
3. The FROM block **logically strengthens or validates** the TO block
4. The relationship is **evidential**: FROM provides justification for believing TO

**Examples**:

✅ **Valid `supports` relationships**:
```
FROM: "95% of users complete onboarding in under 5 minutes"
TO: "Simplified onboarding flow improves user activation"
Reasoning: Metric provides evidence for the conclusion
```

```
FROM: "Code review catches 78% of bugs before production"
TO: "Mandatory code review should be enforced for all PRs"
Reasoning: Finding supports the policy recommendation
```

```
FROM: "Customer survey: 82% prefer dark mode"
TO: "Dark mode should be default theme"
Reasoning: User preference data supports design decision
```

❌ **Invalid `supports` relationships**:
```
FROM: "API endpoint documented"
TO: "API documentation exists"
Reasoning: Tautological, not evidential support
```

```
FROM: "Login page loads in 200ms"
TO: "Checkout flow optimized"
Reasoning: Different features, no logical support relationship
```

**LLM Verification Prompt**:
```
Does the evidence/data in "{FROM}" logically support or validate the claim in "{TO}"?

Criteria:
- FROM must describe factual evidence, data, or observations
- TO must describe a claim, hypothesis, or conclusion
- FROM must strengthen the credibility of TO (not just relate to it)

Answer: Yes/No with confidence 0.0-1.0
```

---

### 3. `contradicts` - Conflicts With Statement

**Semantic Meaning**: A fact, finding, or insight that logically contradicts, conflicts with, or invalidates another statement, assumption, or principle.

**Direction**: Contradicting statement → Contradicted statement (bidirectional: both ways are valid)

**Valid Type Pairs**:
```
FROM types: fact, finding, insight, observation, metric, evidence
TO types: assumption, fact, insight, principle, hypothesis, conclusion
```

**Semantic Criteria** (for LLM verification):
1. The FROM block describes factual information or validated findings
2. The TO block describes a statement, assumption, or belief
3. The FROM block **logically conflicts with or disproves** the TO block
4. The relationship is **logical contradiction**: FROM and TO cannot both be true

**Examples**:

✅ **Valid `contradicts` relationships**:
```
FROM: "90% of users access site via mobile devices"
TO: "Desktop-first design is our priority"
Reasoning: User behavior data contradicts design strategy
```

```
FROM: "Database query returns 0 results for deleted users"
TO: "Soft delete preserves user records in database"
Reasoning: Observed behavior contradicts expected behavior
```

```
FROM: "API response time increased 40% after caching implementation"
TO: "Caching layer improved API performance"
Reasoning: Metric contradicts performance claim
```

❌ **Invalid `contradicts` relationships**:
```
FROM: "Users prefer blue theme"
TO: "Users prefer green theme"
Reasoning: These are alternatives, not contradictions (missing context)
```

```
FROM: "Feature A implemented"
TO: "Feature B implemented"
Reasoning: Both can be true simultaneously, not contradictory
```

**LLM Verification Prompt**:
```
Does "{FROM}" logically contradict or conflict with "{TO}"?

Criteria:
- FROM must describe factual information or validated findings
- TO must describe a statement, assumption, or belief
- FROM and TO cannot both be true simultaneously
- There must be a logical conflict, not just different perspectives

Answer: Yes/No with confidence 0.0-1.0
```

---

### 4. `depends_on` - Prerequisite Dependency

**Semantic Meaning**: A task, action, or objective that requires another task, action, or constraint to be completed or satisfied first (temporal or logical prerequisite).

**Direction**: Dependent → Prerequisite (forward: what does this depend on? backward: what depends on this?)

**Valid Type Pairs**:
```
FROM types: action, objective, task, milestone, feature, decision
TO types: action, objective, constraint, principle, prerequisite, capability
```

**Semantic Criteria** (for LLM verification):
1. The FROM block describes an action, task, or objective
2. The TO block describes a prerequisite condition or prior action
3. The FROM block **cannot be completed without** the TO block being satisfied
4. The relationship is **dependency**: TO must happen/exist before FROM

**Examples**:

✅ **Valid `depends_on` relationships**:
```
FROM: "Deploy new API endpoints to production"
TO: "API endpoints pass integration tests"
Reasoning: Testing is prerequisite for deployment
```

```
FROM: "Migrate users to new authentication system"
TO: "New authentication system supports legacy passwords"
Reasoning: Legacy password support is prerequisite for migration
```

```
FROM: "Train ML model on production data"
TO: "Obtain user consent for data usage"
Reasoning: Legal prerequisite before using production data
```

❌ **Invalid `depends_on` relationships**:
```
FROM: "Improve API performance"
TO: "API exists"
Reasoning: Too trivial/obvious (API existing is not a meaningful prerequisite)
```

```
FROM: "User login feature"
TO: "User registration feature"
Reasoning: Not a strict dependency (login could use external auth)
```

**LLM Verification Prompt**:
```
Does "{FROM}" require "{TO}" to be completed or satisfied first?

Criteria:
- FROM must describe an action, task, or objective
- TO must describe a prerequisite condition or prior action
- FROM cannot be successfully completed without TO
- The dependency must be meaningful (not trivial/obvious)

Answer: Yes/No with confidence 0.0-1.0
```

---

## Relationship Discovery Process

### Phase 1: Semantic Search (Find Candidates)

For a given source block:

1. **Determine relationship types to search for** based on semantic_type:
   ```python
   if semantic_type in ['action', 'solution', 'insight']:
       search_for = ['addresses']  # Look for problems this might address

   if semantic_type in ['fact', 'metric', 'finding']:
       search_for = ['supports', 'contradicts']  # Look for claims this supports/contradicts

   if semantic_type in ['action', 'objective', 'task']:
       search_for = ['depends_on']  # Look for prerequisites
   ```

2. **Semantic search for candidates** (similarity > 0.65):
   ```python
   candidates = await semantic_search(
       basket_id=basket_id,
       query_text=source_block.content,
       filters=SemanticSearchFilters(
           semantic_types=target_types_for_relationship,
           states=['ACCEPTED', 'LOCKED', 'CONSTANT'],
           min_similarity=0.65  # Lower threshold for relationship discovery
       ),
       limit=10
   )
   ```

3. **Result**: 5-10 candidate blocks that might have a relationship

### Phase 2: LLM Verification (Confirm Causality)

For each candidate:

1. **Build verification prompt** with relationship-specific criteria
2. **Call LLM** (gpt-4o-mini for cost-efficiency):
   ```python
   response = openai.chat.completions.create(
       model="gpt-4o-mini",
       messages=[{
           "role": "user",
           "content": verification_prompt
       }],
       response_format={"type": "json_object"},
       temperature=0.1  # Low temperature for consistent verification
   )
   ```

3. **Parse response**:
   ```json
   {
       "exists": true,
       "confidence_score": 0.85,
       "reasoning": "Rate limiting directly mitigates brute force attacks by limiting login attempts per IP address"
   }
   ```

4. **Filter by confidence**:
   - High confidence (>0.90): Auto-accept
   - Medium confidence (0.70-0.90): Propose for user review
   - Low confidence (<0.70): Discard

### Phase 3: Relationship Governance

1. **Create relationship proposal**:
   ```python
   relationship = {
       'from_block_id': source_block.id,
       'to_block_id': candidate.id,
       'relationship_type': 'addresses',
       'confidence_score': 0.85,
       'inference_method': 'llm_verification',
       'state': 'PROPOSED',
       'metadata': {
           'llm_reasoning': "...",
           'semantic_similarity': 0.78,
           'discovered_at': timestamp
       }
   }
   ```

2. **Auto-accept high confidence**:
   ```python
   if confidence_score > 0.90:
       relationship['state'] = 'ACCEPTED'
   ```

3. **Store in database**:
   ```sql
   INSERT INTO substrate_relationships (...) VALUES (...)
   ```

---

## Success Metrics (Week 2 Targets)

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| **Relationship Precision** | >80% | Manual review of 50 random ACCEPTED relationships |
| **Block Coverage** | >60% | % of ACCEPTED blocks with at least 1 relationship |
| **LLM Verification Latency** | <500ms | Average time for gpt-4o-mini verification |
| **False Positive Rate** | <20% | % of ACCEPTED relationships that are invalid |
| **Relationship Distribution** | Balanced | Each of 4 types represents >10% of total |

---

## Cost Model (Week 2)

### LLM Verification Costs

**Model**: gpt-4o-mini
**Cost**: $0.150 / 1M input tokens, $0.600 / 1M output tokens

**Per Relationship**:
- Input: ~500 tokens (prompt + 2 block contents)
- Output: ~50 tokens (JSON response)
- Cost: ~$0.00010 per verification

**At Scale**:
- 1,000 relationships verified: **$0.10**
- 10,000 relationships verified: **$1.00**
- 100,000 relationships verified: **$10.00**

**Total Week 2 Cost** (10K blocks, 60% coverage, avg 1.5 relationships per block):
- Embeddings (from Week 1): $0.20
- Relationship verification: 9,000 relationships × $0.0001 = **$0.90**
- **Total: ~$1.10** (negligible)

---

## Implementation Notes

### Deduplication Strategy

**Problem**: Multiple blocks might infer the same relationship

**Solution**: Database constraint prevents duplicates
```sql
CONSTRAINT unique_relationship UNIQUE (from_block_id, to_block_id, relationship_type)
```

**Behavior**: If relationship already exists, upsert updates confidence if new score is higher

### Bidirectional Relationships

**Question**: Should `contradicts` be bidirectional?

**Answer**: Yes, but stored unidirectionally
- If A contradicts B, then B contradicts A (logically)
- Store once: A → B (contradicts)
- Graph traversal handles both directions

### Relationship Strength vs. Confidence

**Confidence Score**: How certain are we this relationship exists? (LLM verification)
**Relationship Strength**: How strong is the causal link? (Not used in v3.1)

We use confidence_score only - measures verification certainty, not relationship importance.

---

## Edge Cases & Handling

### 1. Self-Referential Blocks

**Example**: "Improve database performance by optimizing queries"

**Issue**: Block might semantically match itself

**Solution**: Database constraint prevents self-reference
```sql
CONSTRAINT no_self_reference CHECK (from_block_id != to_block_id)
```

### 2. Circular Dependencies

**Example**: A depends_on B, B depends_on C, C depends_on A

**Issue**: Logical impossibility (circular dependency)

**Solution**: Allow at database level (graph can have cycles), flag in UI for user review

### 3. Duplicate Relationships with Different Types

**Example**:
- "Rate limiting" **addresses** "Brute force vulnerability"
- "Rate limiting" **supports** "Security policy"

**Issue**: Same blocks, different relationship types

**Solution**: Allowed - blocks can have multiple relationship types simultaneously

### 4. Temporal Decay

**Question**: Do relationships become stale over time?

**Answer**: Not in v3.1 - relationships are timeless unless blocks are deprecated

**Future**: Could add `valid_from` / `valid_until` timestamps

---

## Testing Strategy

### Unit Tests

1. **LLM verification accuracy**:
   - Test with known valid relationships (should return confidence >0.80)
   - Test with known invalid relationships (should return confidence <0.50)
   - Test edge cases (ambiguous relationships)

2. **Relationship ontology validation**:
   - Test type pair enforcement (only valid FROM/TO combinations)
   - Test causal criteria (only causal relationships, not generic)

### Integration Tests

1. **End-to-end relationship inference**:
   - Create block A (problem)
   - Create block B (solution)
   - Trigger P2 inference
   - Verify `addresses` relationship created

2. **Auto-acceptance logic**:
   - High confidence (>0.90) → ACCEPTED
   - Medium confidence (0.70-0.90) → PROPOSED
   - Low confidence (<0.70) → Not created

### Production Validation

1. **Manual review**:
   - Sample 50 random ACCEPTED relationships
   - Validate each relationship manually
   - Measure precision (% valid relationships)

2. **Coverage analysis**:
   - Count blocks with 0 relationships
   - Identify semantic types with low coverage
   - Adjust semantic search thresholds if needed

---

## Appendix: Relationship Examples by Type

### `addresses` Examples

```
"Implement OAuth 2.0 authentication" addresses "Password storage security risk"
"Add pagination to API endpoints" addresses "API timeout with large datasets"
"Introduce code review process" addresses "Production bugs increasing 40% monthly"
"Hire senior backend engineer" addresses "Lack of database optimization expertise"
```

### `supports` Examples

```
"95% uptime last quarter" supports "Infrastructure is stable"
"User feedback: 'Checkout is confusing'" supports "Checkout flow needs redesign"
"API latency p95: 50ms" supports "Performance optimization successful"
"A/B test: Blue button +12% conversion" supports "Use blue for primary CTAs"
```

### `contradicts` Examples

```
"Mobile traffic: 85%" contradicts "Desktop-first design priority"
"Test coverage: 45%" contradicts "All critical paths have tests"
"User drops off at step 3" contradicts "Onboarding flow is intuitive"
"Cache hit rate: 12%" contradicts "Caching significantly reduced load"
```

### `depends_on` Examples

```
"Deploy v2 API" depends_on "Migrate existing clients to v2 schema"
"Train recommendation model" depends_on "User consent for data collection"
"Launch beta program" depends_on "Legal review of terms of service"
"Optimize database queries" depends_on "Identify slow query patterns"
```

---

**End of Relationship Ontology Document**

This ontology will guide LLM verification prompts and ensure relationship quality in Week 2 implementation.
